"""
Simple OCR Comparison Tool for creating JSON reports
"""

import json
import time
import statistics
import os

class SimpleOCRComparisonTool:
    def __init__(self):
        """Khá»Ÿi táº¡o Simple OCR Comparison Tool"""
        print("ğŸ”§ Khá»Ÿi táº¡o Simple OCR Comparison Tool...")
        
        # Thiáº¿t láº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c
        self.base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.results_dir = os.path.join(self.base_dir, "Results")
        self.json_dir = os.path.join(self.results_dir, "Json")
        
        # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
        os.makedirs(self.json_dir, exist_ok=True)
        
        print("âœ… Simple OCR Comparison Tool Ä‘Ã£ sáºµn sÃ ng!")
    
    def compare_ocr_results(self, results):
        """Táº¡o bÃ¡o cÃ¡o so sÃ¡nh tá»« káº¿t quáº£ OCR"""
        print("ğŸ“Š Äang phÃ¢n tÃ­ch káº¿t quáº£...")
        
        # Danh sÃ¡ch engines
        engine_keys = ['easyocr', 'easyocr_preprocessed', 'doctr', 'doctr_preprocessed', 
                      'pytesseract', 'pytesseract_preprocessed', 'opencv', 'gocr', 'keras_ocr']
        
        engine_names = {
            'easyocr': 'EasyOCR (Gá»‘c)',
            'easyocr_preprocessed': 'EasyOCR (Tiá»n xá»­ lÃ½)',
            'doctr': 'DocTR (Gá»‘c)',
            'doctr_preprocessed': 'DocTR (Tiá»n xá»­ lÃ½)',
            'pytesseract': 'Pytesseract (Gá»‘c)',
            'pytesseract_preprocessed': 'Pytesseract (Tiá»n xá»­ lÃ½)',
            'opencv': 'OpenCV (Text Detection)',
            'gocr': 'GOCR (GNU OCR)',
            'keras_ocr': 'Keras OCR'
        }
        
        comparison_data = {
            'metadata': {
                'total_images': len(results),
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'comparison_date': time.time()
            },
            'engines': {}
        }
        
        # PhÃ¢n tÃ­ch tá»«ng engine
        for engine_key in engine_keys:
            engine_data = {
                'name': engine_names.get(engine_key, engine_key),
                'icon': self._get_engine_icon(engine_key),
                'successful_runs': 0,
                'failed_runs': 0,
                'processing_times': [],
                'word_counts': [],
                'confidences': []
            }
            
            # Thu tháº­p dá»¯ liá»‡u tá»« táº¥t cáº£ áº£nh
            for result in results:
                if engine_key in result:
                    engine_result = result[engine_key]
                    if engine_result.get('success'):
                        engine_data['successful_runs'] += 1
                        engine_data['processing_times'].append(engine_result.get('processing_time', 0))
                        
                        # Word count
                        if 'word_count' in engine_result:
                            engine_data['word_counts'].append(engine_result['word_count'])
                        
                        # Confidence (chá»‰ cho cÃ¡c engine OCR thá»±c sá»±)
                        if 'confidence' in engine_result and engine_key != 'opencv':
                            engine_data['confidences'].append(engine_result['confidence'])
                    else:
                        engine_data['failed_runs'] += 1
            
            # TÃ­nh toÃ¡n thá»‘ng kÃª
            if engine_data['processing_times']:
                engine_data['total_time'] = sum(engine_data['processing_times'])
                engine_data['avg_time'] = statistics.mean(engine_data['processing_times'])
                engine_data['avg_processing_time'] = engine_data['avg_time']  # Alias
                engine_data['min_time'] = min(engine_data['processing_times'])
                engine_data['max_time'] = max(engine_data['processing_times'])
            
            if engine_data['word_counts']:
                engine_data['avg_words'] = statistics.mean(engine_data['word_counts'])
                engine_data['avg_word_count'] = engine_data['avg_words']  # Alias
                engine_data['min_words'] = min(engine_data['word_counts'])
                engine_data['max_words'] = max(engine_data['word_counts'])
            
            if engine_data['confidences']:
                engine_data['avg_confidence'] = statistics.mean(engine_data['confidences'])
                engine_data['min_confidence'] = min(engine_data['confidences'])
                engine_data['max_confidence'] = max(engine_data['confidences'])
            
            # Success rate
            total_runs = engine_data['successful_runs'] + engine_data['failed_runs']
            if total_runs > 0:
                engine_data['success_rate'] = engine_data['successful_runs'] / total_runs
            else:
                engine_data['success_rate'] = 0
            
            # ThÃªm vÃ o comparison data
            comparison_data['engines'][engine_key] = engine_data
        
        return comparison_data
    
    def _get_engine_icon(self, engine_key):
        """Láº¥y icon cho engine"""
        icons = {
            'easyocr': 'ğŸ”µ',
            'easyocr_preprocessed': 'ğŸ”µ',
            'doctr': 'ğŸ”´',
            'doctr_preprocessed': 'ğŸ”´',
            'pytesseract': 'ğŸŸ¡',
            'pytesseract_preprocessed': 'ğŸŸ¡',
            'opencv': 'ğŸŸ¢',
            'gocr': 'âšª',
            'keras_ocr': 'ğŸŸ '
        }
        return icons.get(engine_key, 'âšª')
    
    def save_comparison_report(self, comparison_data, filename):
        """LÆ°u bÃ¡o cÃ¡o so sÃ¡nh vÃ o file JSON trong thÆ° má»¥c Results/Json"""
        try:
            # Convert numpy types náº¿u cÃ³
            def convert_numpy_types(obj):
                if hasattr(obj, 'dtype'):
                    return obj.item()
                elif isinstance(obj, dict):
                    return {k: convert_numpy_types(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy_types(v) for v in obj]
                else:
                    return obj
            
            clean_data = convert_numpy_types(comparison_data)
            
            # LÆ°u vÃ o thÆ° má»¥c Json
            file_path = os.path.join(self.json_dir, filename)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(clean_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ BÃ¡o cÃ¡o so sÃ¡nh Ä‘Ã£ lÆ°u: {file_path}")
            return file_path
        
        except Exception as e:
            print(f"âŒ Lá»—i lÆ°u bÃ¡o cÃ¡o: {str(e)}")
            return None
    
    def display_comparison_table(self, comparison_data):
        """Hiá»ƒn thá»‹ báº£ng so sÃ¡nh Ä‘Æ¡n giáº£n"""
        print(f"\n{'='*80}")
        print("ğŸ“Š BÃO CÃO SO SÃNH OCR")
        print(f"{'='*80}")
        print(f"ğŸ•’ Thá»i gian: {comparison_data['metadata']['timestamp']}")
        print(f"ğŸ–¼ï¸  Tá»•ng sá»‘ áº£nh: {comparison_data['metadata']['total_images']}")
        print(f"{'='*80}")
        
        for engine_key, engine_data in comparison_data['engines'].items():
            if engine_data['successful_runs'] > 0:
                print(f"\n{engine_data['icon']} {engine_data['name']}:")
                print(f"   âœ… ThÃ nh cÃ´ng: {engine_data['successful_runs']}/{engine_data['successful_runs'] + engine_data['failed_runs']}")
                
                if 'avg_time' in engine_data:
                    print(f"   â±ï¸  Thá»i gian TB: {engine_data['avg_time']:.3f}s")
                
                if 'avg_words' in engine_data:
                    print(f"   ğŸ“ Sá»‘ tá»« TB: {engine_data['avg_words']:.1f}")
                
                if 'avg_confidence' in engine_data:
                    print(f"   ğŸ¯ Äá»™ chÃ­nh xÃ¡c TB: {engine_data['avg_confidence']:.3f}")
        
        print(f"\nâœ… BÃ¡o cÃ¡o so sÃ¡nh hoÃ n thÃ nh!")